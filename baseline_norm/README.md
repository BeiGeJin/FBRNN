This is the RNN that used in norm situation. Codes are largely adapted from Ankit.
1. The activation function in the recurrent layer is the default sigmoid function, witout modifications in gains and shifts. 
2. Training uses Adam on weights.
3. No Dale's law.